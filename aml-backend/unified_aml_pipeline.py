#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ï–¥–∏–Ω—ã–π AML –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –ê–≥–µ–Ω—Ç—Å—Ç–≤–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –†–ö
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –≤–∏–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ –æ–¥–∏–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å
"""

import os
import json
import time
import logging
import threading
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
from multiprocessing import cpu_count
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import numpy as np
from dataclasses import dataclass, asdict

# –ò–º–ø–æ—Ä—Ç—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
from transaction_profile_afm import TransactionProfile
from customer_profile_afm import CustomerProfile  
from network_profile_afm import NetworkProfile
from behavioral_profile_afm import BehavioralProfile
from geographic_profile_afm import GeographicProfile
from aml_database_setup import AMLDatabaseManager
from aml_json_loader import AMLJSONDataLoader

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class ProcessingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    max_workers: int = cpu_count()
    batch_size: int = 1000
    chunk_size: int = 10000
    enable_caching: bool = True
    validation_level: str = "strict"  # strict, normal, minimal
    risk_threshold: float = 3.0
    
@dataclass 
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –µ–¥–∏–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    client_id: str
    transaction_risk: float
    customer_risk: float  
    network_risk: float
    behavioral_risk: float
    geographic_risk: float
    overall_risk: float
    risk_category: str
    explanations: List[str]
    suspicious_flags: List[str]
    processing_time: float
    timestamp: datetime

class ExplanationEngine:
    """–î–≤–∏–∂–æ–∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –¥–ª—è —Ä–∏—Å–∫–æ–≤"""
    
    def __init__(self):
        self.risk_thresholds = {
            'low': 2.0,
            'medium': 4.0, 
            'high': 6.0,
            'critical': 8.0
        }
        
    def explain_risk(self, result: AnalysisResult) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤"""
        explanations = {
            'overall_assessment': self._get_risk_category(result.overall_risk),
            'risk_breakdown': {
                'transaction': {
                    'score': result.transaction_risk,
                    'impact': '–í—ã—Å–æ–∫–∏–π' if result.transaction_risk > 5.0 else '–°—Ä–µ–¥–Ω–∏–π',
                    'details': self._explain_transaction_risk(result.transaction_risk)
                },
                'customer': {
                    'score': result.customer_risk,
                    'impact': '–í—ã—Å–æ–∫–∏–π' if result.customer_risk > 5.0 else '–°—Ä–µ–¥–Ω–∏–π', 
                    'details': self._explain_customer_risk(result.customer_risk)
                },
                'network': {
                    'score': result.network_risk,
                    'impact': '–í—ã—Å–æ–∫–∏–π' if result.network_risk > 5.0 else '–°—Ä–µ–¥–Ω–∏–π',
                    'details': self._explain_network_risk(result.network_risk)
                },
                'behavioral': {
                    'score': result.behavioral_risk,
                    'impact': '–í—ã—Å–æ–∫–∏–π' if result.behavioral_risk > 5.0 else '–°—Ä–µ–¥–Ω–∏–π',
                    'details': self._explain_behavioral_risk(result.behavioral_risk)
                },
                'geographic': {
                    'score': result.geographic_risk,
                    'impact': '–í—ã—Å–æ–∫–∏–π' if result.geographic_risk > 5.0 else '–°—Ä–µ–¥–Ω–∏–π',
                    'details': self._explain_geographic_risk(result.geographic_risk)
                }
            },
            'suspicious_activities': result.suspicious_flags,
            'recommendations': self._get_recommendations(result),
            'next_actions': self._get_next_actions(result.overall_risk)
        }
        
        return explanations
    
    def _get_risk_category(self, risk_score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ä–∏—Å–∫–∞"""
        if risk_score >= self.risk_thresholds['critical']:
            return '–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô'
        elif risk_score >= self.risk_thresholds['high']:
            return '–í–´–°–û–ö–ò–ô'
        elif risk_score >= self.risk_thresholds['medium']:
            return '–°–†–ï–î–ù–ò–ô'
        else:
            return '–ù–ò–ó–ö–ò–ô'
    
    def _explain_transaction_risk(self, score: float) -> List[str]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏"""
        explanations = []
        if score > 7.0:
            explanations.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        if score > 5.0:
            explanations.append("–í—ã—è–≤–ª–µ–Ω—ã –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ–ø–µ—Ä–∞—Ü–∏–π")
        if score > 3.0:
            explanations.append("–û–ø–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
        return explanations
    
    def _explain_customer_risk(self, score: float) -> List[str]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–µ —Ä–∏—Å–∫–∏"""
        explanations = []
        if score > 7.0:
            explanations.append("–ö–ª–∏–µ–Ω—Ç –≤ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–∞—Ö –∏–ª–∏ PEP")
        if score > 5.0:
            explanations.append("–í—ã—Å–æ–∫–æ—Ä–∏—Å–∫–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞")
        if score > 3.0:
            explanations.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —É–≥–ª—É–±–ª–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞")
        return explanations
    
    def _explain_network_risk(self, score: float) -> List[str]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç —Å–µ—Ç–µ–≤—ã–µ —Ä–∏—Å–∫–∏"""
        explanations = []
        if score > 7.0:
            explanations.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—Ö–µ–º—ã –æ—Ç–º—ã–≤–∞–Ω–∏—è –¥–µ–Ω–µ–≥")
        if score > 5.0:
            explanations.append("–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–µ—Ç–µ–≤—ã–µ —Å–≤—è–∑–∏")
        if score > 3.0:
            explanations.append("–ù–µ—Ç–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π")
        return explanations
    
    def _explain_behavioral_risk(self, score: float) -> List[str]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏"""
        explanations = []
        if score > 7.0:
            explanations.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø–æ–≤–µ–¥–µ–Ω–∏–∏")
        if score > 5.0:
            explanations.append("–ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
        if score > 3.0:
            explanations.append("–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è")
        return explanations
    
    def _explain_geographic_risk(self, score: float) -> List[str]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏"""
        explanations = []
        if score > 7.0:
            explanations.append("–û–ø–µ—Ä–∞—Ü–∏–∏ —Å –≤—ã—Å–æ–∫–æ—Ä–∏—Å–∫–æ–≤—ã–º–∏ —é—Ä–∏—Å–¥–∏–∫—Ü–∏—è–º–∏")
        if score > 5.0:
            explanations.append("–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–∞—Ä—à—Ä—É—Ç—ã")
        if score > 3.0:
            explanations.append("–û–ø–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ–±—É—é—Ç –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
        return explanations
    
    def _get_recommendations(self, result: AnalysisResult) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendations = []
        
        if result.overall_risk >= 8.0:
            recommendations.extend([
                "–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏",
                "–ü–æ–¥–∞—Ç—å –°–ü–û –≤ –ê–§–ú –†–ö",
                "–ü—Ä–æ–≤–µ—Å—Ç–∏ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"
            ])
        elif result.overall_risk >= 6.0:
            recommendations.extend([
                "–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
                "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
                "–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å—Ä–µ–¥—Å—Ç–≤"
            ])
        elif result.overall_risk >= 4.0:
            recommendations.extend([
                "–†–µ–≥—É–ª—è—Ä–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
                "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö"
            ])
        
        return recommendations
    
    def _get_next_actions(self, risk_score: float) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        if risk_score >= 8.0:
            return ["–ë–õ–û–ö–ò–†–û–í–ö–ê", "–°–ü–û", "–†–ê–°–°–õ–ï–î–û–í–ê–ù–ò–ï"]
        elif risk_score >= 6.0:
            return ["–ú–û–ù–ò–¢–û–†–ò–ù–ì", "–ü–†–û–í–ï–†–ö–ê", "–ê–ù–ê–õ–ò–ó"]
        elif risk_score >= 4.0:
            return ["–ù–ê–ë–õ–Æ–î–ï–ù–ò–ï", "–ö–û–ù–¢–†–û–õ–¨"]
        else:
            return ["–û–ë–´–ß–ù–´–ô_–†–ï–ñ–ò–ú"]

class UnifiedRiskCalculator:
    """–ï–¥–∏–Ω—ã–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —Ä–∏—Å–∫–æ–≤"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤ (—Å—É–º–º–∞ = 1.0)
        self.risk_weights = {
            'transaction': 0.25,
            'customer': 0.20,
            'network': 0.20,
            'behavioral': 0.20,
            'geographic': 0.15
        }
        
    def calculate_overall_risk(self, risks: Dict[str, float]) -> Tuple[float, str]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–π —Ä–∏—Å–∫"""
        overall_risk = sum(
            risks.get(risk_type, 0.0) * weight 
            for risk_type, weight in self.risk_weights.items()
        )
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–µ–ª–∏–Ω–µ–π–Ω–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö —Ä–∏—Å–∫–æ–≤
        if overall_risk > 7.0:
            overall_risk = min(10.0, overall_risk * 1.2)
        elif overall_risk > 5.0:
            overall_risk = min(10.0, overall_risk * 1.1)
            
        category = self._determine_category(overall_risk)
        return overall_risk, category
    
    def _determine_category(self, risk_score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ä–∏—Å–∫–∞"""
        if risk_score >= 8.0:
            return "–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô"
        elif risk_score >= 6.0:
            return "–í–´–°–û–ö–ò–ô"
        elif risk_score >= 4.0:
            return "–°–†–ï–î–ù–ò–ô"
        elif risk_score >= 2.0:
            return "–ù–ò–ó–ö–ò–ô"
        else:
            return "–ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô"

class UnifiedAMLPipeline:
    """–ï–¥–∏–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω AML –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self, config: Optional[ProcessingConfig] = None):
        self.config = config or ProcessingConfig()
        self.db_manager = None
        self.json_loader = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ _initialize_database
        self.risk_calculator = UnifiedRiskCalculator(self.config)
        self.explanation_engine = ExplanationEngine()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        self.analyzers = {}
        self._initialize_analyzers()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_processed': 0,
            'suspicious_clients': 0,
            'processing_time': 0.0,
            'start_time': None,
            'errors': 0
        }
        
    def _initialize_analyzers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã"""
        try:
            self.analyzers = {
                'transaction': TransactionProfile(),
                'customer': CustomerProfile(),
                'network': NetworkProfile(), 
                'behavioral': BehavioralProfile(),
                'geographic': GeographicProfile()
            }
            logger.info("‚úÖ –í—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: {e}")
            raise
    
    def _initialize_database(self, db_path: str = "aml_system_unified.db"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.db_manager = AMLDatabaseManager(db_path=db_path)
            self.json_loader = AMLJSONDataLoader(self.db_manager)
            logger.info(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {db_path}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            raise
    
    def process_json_files(self, json_dir: str) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON —Ñ–∞–π–ª–æ–≤"""
        self.stats['start_time'] = time.time()
        
        try:
            # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            self._initialize_database()
            
            # 2. –ü–æ–∏—Å–∫ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è JSON —Ñ–∞–π–ª–æ–≤
            json_files = self._find_json_files(json_dir)
            logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤: {len(json_files)}")
            
            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
            all_results = []
            for json_file in json_files:
                logger.info(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {json_file}")
                file_results = self._process_single_file(json_file)
                all_results.extend(file_results)
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._save_results(all_results)
            
            # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            final_report = self._generate_final_report(all_results)
            
            return final_report
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
            self.stats['errors'] += 1
            raise
        finally:
            self.stats['processing_time'] = time.time() - self.stats['start_time']
    
    def _find_json_files(self, json_dir: str) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        json_path = Path(json_dir)
        if not json_path.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {json_dir}")
        
        json_files = list(json_path.glob("*.json"))
        if not json_files:
            raise ValueError(f"JSON —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤: {json_dir}")
        
        return [str(f) for f in json_files]
    
    def _load_json_file(self, json_file: str) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ê–§–ú
            transactions = []
            for item in data:
                if isinstance(item, dict) and 'row_to_json' in item:
                    transactions.append(item['row_to_json'])
                elif isinstance(item, dict):
                    transactions.append(item)
            
            return transactions
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ JSON —Ñ–∞–π–ª–∞ {json_file}: {e}")
            return []
    
    def _process_single_file(self, json_file: str) -> List[AnalysisResult]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω JSON —Ñ–∞–π–ª"""
        start_time = time.time()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        transactions = self._load_json_file(json_file)
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(transactions):,}")
        
        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–∏ –¥–ª—è –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
        batches = self._create_batches(transactions)
        results = []
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏ —Å –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º
        with ProcessPoolExecutor(max_workers=self.config.max_workers) as executor:
            future_to_batch = {
                executor.submit(self._process_batch, batch): i 
                for i, batch in enumerate(batches)
            }
            
            for future in as_completed(future_to_batch):
                try:
                    batch_results = future.result()
                    results.extend(batch_results)
                    
                    # –ü—Ä–æ–≥—Ä–µ—Å—Å
                    processed = len(results)
                    total = len(transactions)
                    progress = (processed / total) * 100
                    logger.info(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {processed:,}/{total:,} ({progress:.1f}%)")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞: {e}")
                    self.stats['errors'] += 1
        
        processing_time = time.time() - start_time
        logger.info(f"‚è±Ô∏è –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time:.2f} —Å–µ–∫")
        
        return results
    
    def _create_batches(self, transactions: List[Dict]) -> List[List[Dict]]:
        """–°–æ–∑–¥–∞–µ—Ç –±–∞—Ç—á–∏ –¥–ª—è –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞"""
        batches = []
        for i in range(0, len(transactions), self.config.batch_size):
            batch = transactions[i:i + self.config.batch_size]
            batches.append(batch)
        return batches
    
    def _process_batch(self, batch: List[Dict]) -> List[AnalysisResult]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"""
        results = []
        
        for transaction in batch:
            try:
                result = self._analyze_single_transaction(transaction)
                results.append(result)
                
                if result.overall_risk >= self.config.risk_threshold:
                    self.stats['suspicious_clients'] += 1
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {e}")
                self.stats['errors'] += 1
                continue
        
        self.stats['total_processed'] += len(results)
        return results
    
    def _analyze_single_transaction(self, transaction: Dict) -> AnalysisResult:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
        start_time = time.time()
        client_id = transaction.get('debtor_account', 'UNKNOWN')
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –≤–∏–¥—ã –∞–Ω–∞–ª–∏–∑–∞
        risks = {}
        explanations = []
        suspicious_flags = []
        
        # 1. –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        try:
            tx_risk = self.analyzers['transaction'].analyze_transaction(transaction)
            risks['transaction'] = tx_risk.get('risk_score', 0.0)
            if tx_risk.get('suspicious_flags'):
                suspicious_flags.extend(tx_risk['suspicious_flags'])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            risks['transaction'] = 0.0
        
        # 2. –ö–ª–∏–µ–Ω—Ç—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑  
        try:
            customer_risk = self.analyzers['customer'].analyze_customer(client_id)
            risks['customer'] = customer_risk.get('risk_score', 0.0)
            if customer_risk.get('risk_factors'):
                explanations.extend(customer_risk['risk_factors'])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            risks['customer'] = 0.0
        
        # 3. –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑
        try:
            network_risk = self.analyzers['network'].analyze_network_patterns(transaction)
            risks['network'] = network_risk.get('risk_score', 0.0)
            if network_risk.get('network_flags'):
                suspicious_flags.extend(network_risk['network_flags'])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–µ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            risks['network'] = 0.0
        
        # 4. –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        try:
            behavioral_risk = self.analyzers['behavioral'].analyze_behavior(client_id, transaction)
            risks['behavioral'] = behavioral_risk.get('risk_score', 0.0)
            if behavioral_risk.get('anomalies'):
                explanations.extend(behavioral_risk['anomalies'])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            risks['behavioral'] = 0.0
        
        # 5. –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        try:
            geo_risk = self.analyzers['geographic'].analyze_geography(transaction)
            risks['geographic'] = geo_risk.get('risk_score', 0.0)
            if geo_risk.get('geo_flags'):
                suspicious_flags.extend(geo_risk['geo_flags'])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            risks['geographic'] = 0.0
        
        # 6. –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Ä–∏—Å–∫–∞
        overall_risk, risk_category = self.risk_calculator.calculate_overall_risk(risks)
        
        # 7. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = AnalysisResult(
            client_id=client_id,
            transaction_risk=risks.get('transaction', 0.0),
            customer_risk=risks.get('customer', 0.0),
            network_risk=risks.get('network', 0.0),
            behavioral_risk=risks.get('behavioral', 0.0),
            geographic_risk=risks.get('geographic', 0.0),
            overall_risk=overall_risk,
            risk_category=risk_category,
            explanations=explanations,
            suspicious_flags=suspicious_flags,
            processing_time=time.time() - start_time,
            timestamp=datetime.now()
        )
        
        return result
    
    def _save_results(self, results: List[AnalysisResult]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        if not self.db_manager:
            logger.warning("‚ö†Ô∏è –ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
            return
        
        try:
            for result in results:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                self.db_manager.save_analysis_result(asdict(result))
            
            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results):,}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def _generate_final_report(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç"""
        if not results:
            return {"error": "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞"}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∏—Å–∫–∞–º
        risk_stats = {
            'total_analyzed': len(results),
            'suspicious_count': len([r for r in results if r.overall_risk >= self.config.risk_threshold]),
            'risk_distribution': {
                '–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô': len([r for r in results if r.overall_risk >= 8.0]),
                '–í–´–°–û–ö–ò–ô': len([r for r in results if 6.0 <= r.overall_risk < 8.0]),
                '–°–†–ï–î–ù–ò–ô': len([r for r in results if 4.0 <= r.overall_risk < 6.0]),
                '–ù–ò–ó–ö–ò–ô': len([r for r in results if r.overall_risk < 4.0])
            },
            'avg_processing_time': np.mean([r.processing_time for r in results]),
            'avg_risk_scores': {
                'transaction': np.mean([r.transaction_risk for r in results]),
                'customer': np.mean([r.customer_risk for r in results]),
                'network': np.mean([r.network_risk for r in results]),
                'behavioral': np.mean([r.behavioral_risk for r in results]),
                'geographic': np.mean([r.geographic_risk for r in results]),
                'overall': np.mean([r.overall_risk for r in results])
            }
        }
        
        # –¢–æ–ø –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
        top_suspicious = sorted(results, key=lambda x: x.overall_risk, reverse=True)[:20]
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤
        critical_cases = [r for r in results if r.overall_risk >= 8.0]
        detailed_explanations = []
        
        for case in critical_cases[:10]:  # –¢–æ–ø 10 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö
            explanation = self.explanation_engine.explain_risk(case)
            detailed_explanations.append({
                'client_id': case.client_id,
                'risk_score': case.overall_risk,
                'explanation': explanation
            })
        
        report = {
            'summary': risk_stats,
            'top_suspicious': [
                {
                    'client_id': r.client_id,
                    'risk_score': r.overall_risk,
                    'category': r.risk_category,
                    'flags': r.suspicious_flags[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Ñ–ª–∞–≥–æ–≤
                } for r in top_suspicious
            ],
            'detailed_explanations': detailed_explanations,
            'processing_stats': self.stats,
            'timestamp': datetime.now().isoformat(),
            'config': asdict(self.config)
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –≤ JSON
        report_file = f"unified_aml_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        return report

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–ï–¥–∏–Ω—ã–π AML –ø–∞–π–ø–ª–∞–π–Ω')
    parser.add_argument('--json-dir', required=True, help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å JSON —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--workers', type=int, default=cpu_count(), help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤')
    parser.add_argument('--batch-size', type=int, default=1000, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    parser.add_argument('--risk-threshold', type=float, default=3.0, help='–ü–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞')
    
    args = parser.parse_args()
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = ProcessingConfig(
        max_workers=args.workers,
        batch_size=args.batch_size,
        risk_threshold=args.risk_threshold
    )
    
    # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
    pipeline = UnifiedAMLPipeline(config)
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –µ–¥–∏–Ω–æ–≥–æ AML –ø–∞–π–ø–ª–∞–π–Ω–∞")
    print("=" * 50)
    print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è JSON: {args.json_dir}")
    print(f"üë• –í–æ—Ä–∫–µ—Ä–æ–≤: {config.max_workers}")
    print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {config.batch_size}")
    print(f"‚ö†Ô∏è –ü–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞: {config.risk_threshold}")
    print("=" * 50)
    
    try:
        report = pipeline.process_json_files(args.json_dir)
        
        print("\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("=" * 50)
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {report['summary']['total_analyzed']:,}")
        print(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö: {report['summary']['suspicious_count']:,}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è: {pipeline.stats['processing_time']:.2f} —Å–µ–∫")
        print(f"üî• –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {report['summary']['total_analyzed']/pipeline.stats['processing_time']:.0f} —Ç—Ä/—Å–µ–∫")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())