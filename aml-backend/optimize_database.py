import sqlite3
import time
from typing import List, Dict
import functools
from datetime import datetime

def create_database_indexes(db_path: str = 'aml_system.db'):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤"""
    print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    indexes = [
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è customer_profiles
        ("idx_customer_risk", "CREATE INDEX IF NOT EXISTS idx_customer_risk ON customer_profiles(overall_risk_score DESC)"),
        ("idx_customer_id", "CREATE INDEX IF NOT EXISTS idx_customer_id ON customer_profiles(customer_id)"),
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è transactions
        ("idx_transactions_sender", "CREATE INDEX IF NOT EXISTS idx_transactions_sender ON transactions(sender_id)"),
        ("idx_transactions_beneficiary", "CREATE INDEX IF NOT EXISTS idx_transactions_beneficiary ON transactions(beneficiary_id)"),
        ("idx_transactions_date", "CREATE INDEX IF NOT EXISTS idx_transactions_date ON transactions(transaction_date DESC)"),
        ("idx_transactions_suspicious", "CREATE INDEX IF NOT EXISTS idx_transactions_suspicious ON transactions(is_suspicious)"),
        ("idx_transactions_amount", "CREATE INDEX IF NOT EXISTS idx_transactions_amount ON transactions(amount_kzt DESC)"),
        
        # –°–æ—Å—Ç–∞–≤–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        ("idx_transactions_client_date", "CREATE INDEX IF NOT EXISTS idx_transactions_client_date ON transactions(sender_id, transaction_date DESC)"),
        ("idx_transactions_beneficiary_date", "CREATE INDEX IF NOT EXISTS idx_transactions_beneficiary_date ON transactions(beneficiary_id, transaction_date DESC)"),
    ]
    
    for index_name, sql in indexes:
        try:
            start_time = time.time()
            cursor.execute(sql)
            end_time = time.time()
            print(f"  ‚úÖ {index_name}: {end_time - start_time:.3f}s")
        except Exception as e:
            print(f"  ‚ùå {index_name}: {e}")
    
    conn.commit()
    conn.close()
    print("‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã!")

def analyze_batch_optimized(client_ids: List[str], db_path: str = 'aml_system.db') -> List[Dict]:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π batch-–∞–Ω–∞–ª–∏–∑ —Å –æ–¥–Ω–∏–º SQL-–∑–∞–ø—Ä–æ—Å–æ–º
    """
    if not client_ids:
        return []
    
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # –°–æ–∑–¥–∞–µ–º placeholders –¥–ª—è IN-–∑–∞–ø—Ä–æ—Å–∞
    placeholders = ','.join(['?' for _ in client_ids])
    
    # –û–¥–∏–Ω –±–æ–ª—å—à–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
    query = f"""
    SELECT 
        cp.customer_id,
        cp.overall_risk_score,
        cp.is_pep,
        cp.is_foreign,
        COUNT(DISTINCT t.transaction_id) as tx_count,
        SUM(CASE WHEN t.sender_id = cp.customer_id THEN t.amount_kzt ELSE 0 END) as total_sent,
        SUM(CASE WHEN t.beneficiary_id = cp.customer_id THEN t.amount_kzt ELSE 0 END) as total_received,
        SUM(CASE WHEN t.is_suspicious = 1 THEN 1 ELSE 0 END) as suspicious_count,
        COUNT(DISTINCT CASE WHEN t.sender_id = cp.customer_id THEN t.beneficiary_id 
                           WHEN t.beneficiary_id = cp.customer_id THEN t.sender_id END) as counterparties_count,
        MAX(t.amount_kzt) as max_transaction,
        AVG(t.amount_kzt) as avg_transaction
    FROM customer_profiles cp
    LEFT JOIN transactions t ON (t.sender_id = cp.customer_id OR t.beneficiary_id = cp.customer_id)
    WHERE cp.customer_id IN ({placeholders})
    GROUP BY cp.customer_id, cp.overall_risk_score, cp.is_pep, cp.is_foreign
    ORDER BY cp.overall_risk_score DESC
    """
    
    cursor.execute(query, client_ids)
    rows = cursor.fetchall()
    conn.close()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = []
    for row in rows:
        # –†–∞—Å—á–µ—Ç —Ä–∏—Å–∫-—Å–∫–æ—Ä–∞
        base_risk = row['overall_risk_score'] if row['overall_risk_score'] else 0
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏
        tx_risk = 3 if row['tx_count'] > 50 else 0
        behavior_risk = min(row['suspicious_count'] * 2, 10) if row['suspicious_count'] else 0
        volume_risk = 2 if (row['total_sent'] + row['total_received']) > 50000000 else 0
        network_risk = 1 if row['counterparties_count'] > 20 else 0
        
        # PEP –∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω—Ü—ã
        pep_risk = 5 if row['is_pep'] else 0
        foreign_risk = 2 if row['is_foreign'] else 0
        
        total_risk_score = base_risk + tx_risk + behavior_risk + volume_risk + network_risk + pep_risk + foreign_risk
        
        result = {
            'client_id': row['customer_id'],
            'total_risk_score': total_risk_score,
            'transactions_count': row['tx_count'] or 0,
            'counterparties_count': row['counterparties_count'] or 0,
            'total_volume': (row['total_sent'] or 0) + (row['total_received'] or 0),
            'suspicious_transactions': row['suspicious_count'] or 0,
            'is_suspicious': total_risk_score > 10,
            'max_transaction': row['max_transaction'] or 0,
            'avg_transaction': row['avg_transaction'] or 0,
            'risk_factors': {
                'base_risk': base_risk,
                'transaction_risk': tx_risk,
                'behavior_risk': behavior_risk,
                'volume_risk': volume_risk,
                'network_risk': network_risk,
                'pep_risk': pep_risk,
                'foreign_risk': foreign_risk
            }
        }
        results.append(result)
    
    return results

@functools.lru_cache(maxsize=1000)
def cached_client_analysis(client_id: str, cache_hour: int, db_path: str = 'aml_system.db'):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª–∏–µ–Ω—Ç–∞ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å)"""
    return analyze_batch_optimized([client_id], db_path)[0] if analyze_batch_optimized([client_id], db_path) else None

def get_cached_analysis(client_id: str, db_path: str = 'aml_system.db'):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    current_hour = datetime.now().hour
    return cached_client_analysis(client_id, current_hour, db_path)

def test_optimization_performance():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ô –í–ï–†–°–ò–ò")
    print("=" * 50)
    
    db_path = 'aml_system.db'
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
    create_database_indexes(db_path)
    print()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT customer_id FROM customer_profiles ORDER BY overall_risk_score DESC LIMIT 1000")
    client_ids = [row[0] for row in cursor.fetchall()]
    conn.close()
    
    print(f"üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(client_ids)} –∫–ª–∏–µ–Ω—Ç–∞—Ö")
    print()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –±–∞—Ç—á–µ–π
    test_sizes = [100, 500, 1000]
    
    for test_size in test_sizes:
        if test_size > len(client_ids):
            continue
            
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {test_size} –∫–ª–∏–µ–Ω—Ç–æ–≤:")
        
        test_client_ids = client_ids[:test_size]
        
        # –¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏
        start_time = time.time()
        results = analyze_batch_optimized(test_client_ids, db_path)
        end_time = time.time()
        
        batch_time = end_time - start_time
        speed = len(results) / batch_time if batch_time > 0 else 0
        
        print(f"  ‚ö° Batch SQL: {batch_time:.3f}s ({speed:.1f} –∫–ª/—Å–µ–∫)")
        
        # –¢–µ—Å—Ç —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º (–≤—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫)
        start_time = time.time()
        cached_results = [get_cached_analysis(cid, db_path) for cid in test_client_ids[:10]]
        end_time = time.time()
        
        cache_time = end_time - start_time
        cache_speed = 10 / cache_time if cache_time > 0 else 0
        
        print(f"  üíæ –° –∫—ç—à–µ–º (10 –∫–ª): {cache_time:.3f}s ({cache_speed:.1f} –∫–ª/—Å–µ–∫)")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        suspicious_count = sum(1 for r in results if r['is_suspicious'])
        high_risk_count = sum(1 for r in results if r['total_risk_score'] > 15)
        
        print(f"  üìä –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö: {suspicious_count}/{len(results)} ({suspicious_count/len(results)*100:.1f}%)")
        print(f"  üî¥ –í—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞: {high_risk_count}/{len(results)} ({high_risk_count/len(results)*100:.1f}%)")
        print()
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –Ω–µ–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π
    print("üìà –°–†–ê–í–ù–ï–ù–ò–ï –° –ë–ê–ó–û–í–û–ô –í–ï–†–°–ò–ï–ô:")
    print("-" * 40)
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    try:
        from simple_performance_test import analyze_single_client_simple
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º 100 –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø—Ä–æ—Å—Ç–æ–π –≤–µ—Ä—Å–∏–µ–π
        test_client_ids = client_ids[:100]
        
        start_time = time.time()
        simple_results = []
        for cid in test_client_ids:
            result = analyze_single_client_simple(cid, db_path)
            if result:
                simple_results.append(result)
        simple_time = time.time() - start_time
        simple_speed = len(simple_results) / simple_time
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π
        start_time = time.time()
        optimized_results = analyze_batch_optimized(test_client_ids, db_path)
        optimized_time = time.time() - start_time
        optimized_speed = len(optimized_results) / optimized_time
        
        speedup = simple_time / optimized_time if optimized_time > 0 else 0
        
        print(f"üêå –ü—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è: {simple_time:.3f}s ({simple_speed:.1f} –∫–ª/—Å–µ–∫)")
        print(f"‚ö° –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è: {optimized_time:.3f}s ({optimized_speed:.1f} –∫–ª/—Å–µ–∫)")
        print(f"üöÄ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.1f}x")
        
        if speedup > 3:
            print("‚úÖ –û—Ç–ª–∏—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è!")
        elif speedup > 2:
            print("‚úÖ –•–æ—Ä–æ—à–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è!")
        elif speedup > 1.5:
            print("‚ö†Ô∏è –£–º–µ—Ä–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
        else:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
            
    except ImportError:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    
    print()
    print("üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("1. ‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã - –∑–∞–ø—Ä–æ—Å—ã —É—Å–∫–æ—Ä–µ–Ω—ã")
    print("2. ‚úÖ Batch SQL - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    print("3. ‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ - –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —É—Å–∫–æ—Ä–µ–Ω—ã –≤ —Ä–∞–∑—ã")
    print("4. üîÑ –î–ª—è >10,000 –∫–ª–∏–µ–Ω—Ç–æ–≤ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—é")

if __name__ == "__main__":
    test_optimization_performance() 