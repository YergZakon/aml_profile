import os
import json
from flask import Flask, request, jsonify, send_file, make_response, Blueprint
from flask_cors import CORS
from werkzeug.utils import secure_filename
from datetime import datetime
import hashlib
import shutil
import random  # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
import threading # <-- 1. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º threading
import sys
import glob

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from aml_integration_system import run_full_analysis # <-- 2. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é

app = Flask(__name__)

# –°–æ–∑–¥–∞–µ–º Blueprint –¥–ª—è API —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º /api
api_bp = Blueprint('api', __name__, url_prefix='/api')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–æ–º
CORS(app, resources={
    r"/*": {
        "origins": ["http://localhost:3000"],
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS", "HEAD", "PATCH"],
        "allow_headers": [
            "Content-Type", "Authorization", "Upload-Offset", "Upload-Length", 
            "Tus-Resumable", "X-File-Name", "X-File-Size", "X-Upload-Time", 
            "X-Department", "Upload-Metadata"
        ],
        "expose_headers": [
            "Location", "Upload-Offset", "Tus-Resumable", "Upload-Length",
            "Tus-Version", "Tus-Max-Size", "Tus-Extension", "Upload-Metadata"
        ]
    }
})

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
UPLOAD_FOLDER = 'uploads'
CHUNKS_FOLDER = 'chunks'
PROCESSING_FOLDER = 'processing'
RESULTS_FOLDER = 'results'

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
for folder in [UPLOAD_FOLDER, CHUNKS_FOLDER, PROCESSING_FOLDER, RESULTS_FOLDER]:
    os.makedirs(folder, exist_ok=True)

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∑–∫–∞—Ö (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ - –ë–î)
uploads = {}
processing_tasks = {}

# === –ù–û–í–û–ï: –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ë–î —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ ===
latest_db_path = None  # –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞

test_transactions = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π

# –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è TUS-–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∫ OPTIONS –æ—Ç–≤–µ—Ç–∞–º
@app.after_request
def add_tus_headers(response):
    if request.method == 'OPTIONS' and request.path.startswith('/upload'):
        response.headers['Tus-Resumable'] = '1.0.0'
        response.headers['Tus-Version'] = '1.0.0'
        response.headers['Tus-Extension'] = 'creation,creation-with-upload'
        response.headers['Tus-Max-Size'] = '1073741824'  # 1GB
    return response

# –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è TUS –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (–±–µ–∑ /api –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Uppy)
@app.route('/upload', methods=['POST', 'HEAD', 'PATCH']) # <-- –£–±—Ä–∞–ª–∏ OPTIONS
@app.route('/upload/<file_id>', methods=['POST', 'HEAD', 'PATCH']) # <-- –£–±—Ä–∞–ª–∏ OPTIONS
def tus_upload(file_id=None):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ TUS –∑–∞–≥—Ä—É–∑–æ–∫"""
    
    print(f"TUS –∑–∞–ø—Ä–æ—Å: {request.method} {request.path}")
    print(f"–ó–∞–≥–æ–ª–æ–≤–∫–∏: {dict(request.headers)}")
    
    if request.method == 'HEAD':
        if not file_id or file_id not in uploads:
            return '', 404
        
        upload_info = uploads[file_id]
        response = make_response('')
        response.headers['Upload-Offset'] = str(upload_info['offset'])
        response.headers['Upload-Length'] = str(upload_info['size'])
        response.headers['Tus-Resumable'] = '1.0.0'
        response.headers['Cache-Control'] = 'no-store'
        return response
    
    if request.method == 'POST':
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        upload_length = request.headers.get('Upload-Length')
        upload_metadata = request.headers.get('Upload-Metadata', '')
        
        if not upload_length:
            return jsonify({'error': 'Upload-Length header required'}), 400
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
        file_id = hashlib.sha256(f"{datetime.now().isoformat()}{upload_metadata}".encode()).hexdigest()[:16]
        
        # –ü–∞—Ä—Å–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {}
        if upload_metadata:
            for item in upload_metadata.split(','):
                if ' ' in item:
                    key, value = item.split(' ', 1)
                    try:
                        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
                        import base64
                        decoded_value = base64.b64decode(value).decode('utf-8')
                        metadata[key] = decoded_value
                    except:
                        metadata[key] = value
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∑–∫–µ
        uploads[file_id] = {
            'id': file_id,
            'size': int(upload_length),
            'offset': 0,
            'metadata': metadata,
            'created_at': datetime.now().isoformat(),
            'chunks_path': os.path.join(CHUNKS_FOLDER, file_id)
        }
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —á–∞–Ω–∫–æ–≤
        os.makedirs(uploads[file_id]['chunks_path'], exist_ok=True)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        response = make_response('', 201)
        response.headers['Location'] = f'/upload/{file_id}'
        response.headers['Tus-Resumable'] = '1.0.0'
        
        return response
    
    if request.method == 'PATCH':
        if not file_id or file_id not in uploads:
            return jsonify({'error': 'Upload not found'}), 404
        
        upload_info = uploads[file_id]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º offset
        upload_offset = int(request.headers.get('Upload-Offset', 0))
        if upload_offset != upload_info['offset']:
            return jsonify({'error': 'Offset mismatch'}), 409
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫
        chunk_path = os.path.join(upload_info['chunks_path'], f"chunk_{upload_offset}")
        
        with open(chunk_path, 'wb') as f:
            chunk_data = request.get_data()
            f.write(chunk_data)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º offset
        upload_info['offset'] += len(chunk_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞
        if upload_info['offset'] >= upload_info['size']:
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª –∏–∑ —á–∞–Ω–∫–æ–≤
            final_filename = upload_info['metadata'].get('filename', f"{file_id}.dat")
            final_path = os.path.join(UPLOAD_FOLDER, secure_filename(final_filename))
            
            with open(final_path, 'wb') as final_file:
                chunk_files = sorted(os.listdir(upload_info['chunks_path']), key=lambda x: int(x.split('_')[1])) # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
                for chunk_file in chunk_files:
                    chunk_path = os.path.join(upload_info['chunks_path'], chunk_file)
                    with open(chunk_path, 'rb') as chunk:
                        final_file.write(chunk.read())
            
            # –û—á–∏—â–∞–µ–º —á–∞–Ω–∫–∏
            shutil.rmtree(upload_info['chunks_path'])
            
            # –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            upload_info['status'] = 'processing'
            upload_info['final_path'] = final_path
            
            # 3. –ó–∞–º–µ–Ω—è–µ–º —Å–∏–º—É–ª—è—Ü–∏—é –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ
            task_id = file_id # –ò—Å–ø–æ–ª—å–∑—É–µ–º file_id –∫–∞–∫ ID –∑–∞–¥–∞—á–∏
            processing_tasks[task_id] = {
                'status': 'queued',
                'progress': 0,
                'message': '–§–∞–π–ª –ø–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ –∞–Ω–∞–ª–∏–∑...'
            }
            
            # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞
            db_path = os.path.join(os.path.dirname(__file__), f"aml_system_{task_id}.db") # –ë–î –≤ –ø–∞–ø–∫–µ aml-backend
            analysis_thread = threading.Thread(
                target=run_analysis_and_update_status,
                args=(task_id, final_path, db_path)
            )
            analysis_thread.start()
            
            print(f"–§–∞–π–ª {final_filename} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω, –∑–∞–ø—É—â–µ–Ω –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ (ID: {task_id})")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        response = make_response('', 204)
        response.headers['Upload-Offset'] = str(upload_info['offset'])
        response.headers['Tus-Resumable'] = '1.0.0'
        
        return response
    
    return jsonify({'error': 'Method not allowed'}), 405

def run_analysis_and_update_status(task_id, json_filepath, db_filepath):
    """
    –§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ.
    –û–Ω–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏.
    """
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "–≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ"
        processing_tasks[task_id]['status'] = 'processing'
        processing_tasks[task_id]['message'] = '–ò–¥–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...'
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—è–∂–µ–ª—É—é –∑–∞–¥–∞—á—É
        report_path = run_full_analysis(json_filepath, db_filepath)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "–∑–∞–≤–µ—Ä—à–µ–Ω–æ"
        processing_tasks[task_id]['status'] = 'completed'
        processing_tasks[task_id]['message'] = '–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω.'
        processing_tasks[task_id]['progress'] = 100
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Ç—å –∫ –æ—Ç—á–µ—Ç—É –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open(report_path, 'r', encoding='utf-8') as f:
            results_summary = json.load(f)

        processing_tasks[task_id]['results'] = results_summary

    except Exception as e:
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        print(f"–û–®–ò–ë–ö–ê –≤ –ø–æ—Ç–æ–∫–µ –∞–Ω–∞–ª–∏–∑–∞ (ID: {task_id}): {e}")
        processing_tasks[task_id]['status'] = 'failed'
        processing_tasks[task_id]['message'] = f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}"

    finally:
        # === –ù–û–í–û–ï: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–π –ë–î ===
        global latest_db_path
        latest_db_path = db_filepath

@api_bp.route('/processing-status/<file_id>', methods=['GET'])
def get_processing_status(file_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞"""
    if file_id not in processing_tasks:
        return jsonify({'error': 'Task not found'}), 404
    
    task = processing_tasks[file_id]
    
    # –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–∞, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –≤ –ø–æ—Ç–æ–∫–µ
    # (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –≥—Ä–∞–Ω—É–ª—è—Ä–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ run_full_analysis –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏)

    return jsonify(task)

@api_bp.route('/files', methods=['GET'])
def get_files():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    files = []
    for file_id, upload_info in uploads.items():
        files.append({
            'id': file_id,
            'filename': upload_info['metadata'].get('filename', 'Unknown'),
            'size': upload_info['size'],
            'created_at': upload_info['created_at'],
            'status': upload_info.get('status', 'uploading')
        })
    
    return jsonify({
        'files': files,
        'total': len(files)
    })

@api_bp.route('/analytics/dashboard', methods=['GET'])
def get_dashboard_data():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –ë–î (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)"""
    global latest_db_path
    if latest_db_path and os.path.exists(latest_db_path):
        from aml_database_setup import AMLDatabaseManager
        db = AMLDatabaseManager(db_path=latest_db_path)
        stats = db.get_system_statistics()
        db.close()

        return jsonify({
            'summary': {
                'total_transactions': stats['transactions']['total_transactions'],
                'flagged_transactions': stats['transactions']['suspicious_transactions'],
                'total_amount': stats['transactions']['total_volume'],
                'alerts_pending': stats['alerts']['new_alerts']
            },
            'risk_distribution': {
                'high': stats['transactions']['suspicious_transactions'],  # —É–ø—Ä–æ—â—ë–Ω–Ω–æ
                'medium': 0,
                'low': stats['transactions']['total_transactions'] - stats['transactions']['suspicious_transactions']
            },
            'recent_alerts': [],  # TODO: –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
            'trends': {},
            'last_updated': datetime.now().isoformat()
        })

    # –§–æ–ª–±–µ–∫ –∫ –∑–∞–≥–ª—É—à–∫–µ, –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–π –ë–î
    return jsonify({
        'summary': {
            'total_transactions': 0,
            'flagged_transactions': 0,
            'total_amount': 0,
            'alerts_pending': 0
        },
        'risk_distribution': {
            'high': 0,
            'medium': 0,
            'low': 0
        },
        'recent_alerts': [],
        'trends': {},
        'last_updated': datetime.now().isoformat()
    })

@api_bp.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })

@api_bp.route('/')
def api_index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': '–ê–§–ú –†–ö - API —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π',
        'version': '1.0.0',
        'endpoints': {
            'health': '/api/health',
            'upload': '/upload',
            'files': '/api/files',
            'processing_status': '/api/processing-status/<file_id>',
            'dashboard': '/api/analytics/dashboard',
            'risk_analysis': '/api/analytics/risk-analysis',
            'transactions': '/api/transactions',
            'transaction_details': '/api/transactions/<transaction_id>',
            'transaction_review': '/api/transactions/<transaction_id>/review',
            'transactions_export': '/api/transactions/export'
        },
        'frontend_url': 'http://localhost:3000'
    })

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
def generate_test_transactions(count=100):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    transactions = []
    
    # –°–ø–∏—Å–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    names = [
        '–¢–û–û "–ö–∞–∑–¢—Ä–µ–π–¥"', '–ê–û "–ê–ª–º–∞–ò–Ω–≤–µ—Å—Ç"', '–ò–ü –ò–≤–∞–Ω–æ–≤ –ò.–ò.', '–¢–û–û "–ù—É—Ä–°—Ç—Ä–æ–π"',
        '–ê–û "–ö–∞–∑–ú—É–Ω–∞–π–ì–∞–∑"', '–¢–û–û "–ê—Å—Ç–∞–Ω–∞–ë–∏–∑–Ω–µ—Å"', '–ò–ü –ü–µ—Ç—Ä–æ–≤ –ü.–ü.', '–ê–û "–ö–∞–∑–∞—Ö–¢–µ–ª–µ–∫–æ–º"',
        '–¢–û–û "–ê–ª–º–∞—Ç—ã–¢—Ä–∞–Ω—Å"', '–ò–ü –°–∏–¥–æ—Ä–æ–≤ –°.–°.'
    ]
    
    banks = ['–•–∞–ª—ã–∫ –ë–∞–Ω–∫', 'Kaspi Bank', '–ë–¶–ö', 'Forte Bank', 'Jusan Bank']
    risk_reasons = [
        '–ö—Ä—É–ø–Ω–∞—è –Ω–∞–ª–∏—á–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è',
        '–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã',
        '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ö–µ–º–∞',
        '–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ—Ñ–∏–ª—é –∫–ª–∏–µ–Ω—Ç–∞',
        '–°–≤—è–∑—å —Å –≤—ã—Å–æ–∫–æ—Ä–∏—Å–∫–æ–≤–æ–π —é—Ä–∏—Å–¥–∏–∫—Ü–∏–µ–π'
    ]
    
    for i in range(count):
        risk_level = random.choices(['low', 'medium', 'high'], weights=[0.7, 0.2, 0.1])[0]
        amount = random.uniform(100000, 50000000) if risk_level == 'high' else random.uniform(10000, 5000000)
        
        transaction = {
            'id': f'TRX-2024-{str(i+1).zfill(6)}',
            'reference_id': f'REF-{random.randint(100000, 999999)}',
            'date': f'2024-01-{random.randint(1, 15):02d}T{random.randint(0, 23):02d}:{random.randint(0, 59):02d}:00',
            'sender': {
                'name': random.choice(names),
                'account': f'KZ{random.randint(100, 999)}XXX{random.randint(1000000, 9999999)}',
                'bank': random.choice(banks),
                'type': random.choice(['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ', '–ò–ü', '–§–∏–∑–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ'])
            },
            'receiver': {
                'name': random.choice(names),
                'account': f'KZ{random.randint(100, 999)}XXX{random.randint(1000000, 9999999)}',
                'bank': random.choice(banks),
                'type': random.choice(['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ', '–ò–ü', '–§–∏–∑–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ'])
            },
            'amount': round(amount, 2),
            'currency': 'KZT',
            'risk_level': risk_level,
            'risk_score': random.uniform(0.7, 0.95) if risk_level == 'high' else random.uniform(0.3, 0.7),
            'risk_reasons': random.sample(risk_reasons, k=random.randint(1, 3)) if risk_level != 'low' else [],
            'status': random.choice(['pending', 'reviewing', 'cleared', 'reported']),
            'description': f'–ü–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤ –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É ‚Ññ{random.randint(1000, 9999)}'
        }
        
        transactions.append(transaction)
    
    return sorted(transactions, key=lambda x: x['date'], reverse=True)

@api_bp.route('/transactions', methods=['GET'])
def get_transactions():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ë–î —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
    global latest_db_path

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
    page = int(request.args.get('page', 1))
    limit = int(request.args.get('limit', 50))

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ –ø–æ–∏—Å–∫–∞
    risk_level = request.args.get('risk_level', '')
    start_date = request.args.get('start_date', '')
    end_date = request.args.get('end_date', '')
    search = request.args.get('search', '').lower()

    transactions_source = []

    if latest_db_path and os.path.exists(latest_db_path):
        from aml_database_setup import AMLDatabaseManager
        db = AMLDatabaseManager(db_path=latest_db_path)
        transactions_source = db.get_all_transactions()
        db.close()

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—é —Ä–∏—Å–∫–∞
    if risk_level:
        transactions_source = [t for t in transactions_source if str(t.get('final_risk_score', 0)).lower() == risk_level.lower() or t.get('risk_level') == risk_level]

    # –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä–æ–∫–µ
    if search:
        transactions_source = [t for t in transactions_source if search in str(t).lower()]

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–∞–º
    def parse_date(val):
        try:
            return datetime.fromisoformat(val) if isinstance(val, str) else val
        except ValueError:
            return None

    if start_date:
        start_dt = parse_date(start_date)
        transactions_source = [t for t in transactions_source if parse_date(t.get('transaction_date') or t.get('date')) >= start_dt]
    if end_date:
        end_dt = parse_date(end_date)
        transactions_source = [t for t in transactions_source if parse_date(t.get('transaction_date') or t.get('date')) <= end_dt]

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ (desc)
    transactions_source.sort(key=lambda x: parse_date(x.get('transaction_date') or x.get('date')) or datetime.min, reverse=True)

    total = len(transactions_source)
    start = (page - 1) * limit
    end = start + limit

    return jsonify({
        'transactions': transactions_source[start:end],
        'pagination': {
            'page': page,
            'limit': limit,
            'total': total,
            'pages': (total + limit - 1) // limit
        }
    })

@api_bp.route('/transactions/<transaction_id>', methods=['GET'])
def get_transaction_details(transaction_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏–∑ –ë–î"""
    global latest_db_path

    transaction_data = None
    if latest_db_path and os.path.exists(latest_db_path):
        from aml_database_setup import AMLDatabaseManager
        db = AMLDatabaseManager(db_path=latest_db_path)
        cursor = db.connection.cursor()
        cursor.execute("SELECT * FROM transactions WHERE transaction_id = ?", (transaction_id,))
        row = cursor.fetchone()
        if row:
            transaction_data = dict(row)
        db.close()

    if not transaction_data:
        return jsonify({'error': 'Transaction not found'}), 404

    return jsonify(transaction_data)

@api_bp.route('/transactions/<transaction_id>/review', methods=['POST'])
def mark_transaction_reviewed(transaction_id):
    """–û—Ç–º–µ—á–∞–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∫–∞–∫ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é"""
    global latest_db_path
    
    if not latest_db_path or not os.path.exists(latest_db_path):
        return jsonify({'error': 'Database not initialized'}), 503
    
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –±—ã –æ–±–Ω–æ–≤–ª—è–ª–∞—Å—å –ë–î
    review_data = request.json
    print(f"–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è {transaction_id} –æ—Ç–º–µ—á–µ–Ω–∞ –∫–∞–∫ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è")
    print(f"–ü—Ä–æ–≤–µ—Ä–∏–ª: {review_data.get('reviewedBy')}")
    print(f"–í—Ä–µ–º—è: {review_data.get('reviewedAt')}")
    print(f"–ó–∞–º–µ—Ç–∫–∏: {review_data.get('notes')}")
    
    return jsonify({'status': 'success', 'message': 'Transaction marked as reviewed'})

@api_bp.route('/transactions/export', methods=['GET'])
def export_transactions():
    """–≠–∫—Å–ø–æ—Ä—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ CSV –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –ë–î –ª–∏–±–æ –∏–∑ –º–æ–∫-–¥–∞–Ω–Ω—ã—Ö"""
    import io
    import csv
    global latest_db_path

    risk_level = request.args.get('riskLevel', '')

    transactions_source = []
    if latest_db_path and os.path.exists(latest_db_path):
        from aml_database_setup import AMLDatabaseManager
        db = AMLDatabaseManager(db_path=latest_db_path)
        transactions_source = db.get_all_transactions()
        db.close()

    if risk_level:
        transactions_source = [t for t in transactions_source if str(t.get('final_risk_score', 0)).lower() == risk_level.lower() or t.get('risk_level') == risk_level]

    # –°–æ–∑–¥–∞–µ–º CSV
    output = io.StringIO()
    writer = csv.writer(output)
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    writer.writerow([
        'ID —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏', '–î–∞—Ç–∞', '–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å', '–ë–∞–Ω–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è',
        '–ü–æ–ª—É—á–∞—Ç–µ–ª—å', '–ë–∞–Ω–∫ –ø–æ–ª—É—á–∞—Ç–µ–ª—è', '–°—É–º–º–∞', '–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞'
    ])
    
    # –î–∞–Ω–Ω—ã–µ
    for t in transactions_source[:100]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 100 –∑–∞–ø–∏—Å—è–º–∏
        writer.writerow([
            t.get('reference_id') or t.get('transaction_id'),
            t.get('date') or t.get('transaction_date'),
            t.get('sender', {}).get('name') or t.get('sender_name'),
            t.get('sender', {}).get('bank') or t.get('sender_bank_bic'),
            t.get('receiver', {}).get('name') or t.get('beneficiary_name'),
            t.get('receiver', {}).get('bank') or t.get('beneficiary_bank_bic'),
            t.get('amount') or t.get('amount_kzt'),
            t.get('risk_level') or ('HIGH' if t.get('is_suspicious') else 'LOW')
        ])
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Ñ–∞–π–ª
    output.seek(0)
    response = make_response(output.getvalue())
    response.headers['Content-Disposition'] = 'attachment; filename=transactions.csv'
    response.headers['Content-Type'] = 'text/csv; charset=utf-8'
    
    return response

@api_bp.route('/analytics/risk-analysis', methods=['GET'])
def get_risk_analysis():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ë–î"""
    global latest_db_path
    
    if latest_db_path and os.path.exists(latest_db_path):
        from aml_database_setup import AMLDatabaseManager
        db = AMLDatabaseManager(db_path=latest_db_path)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∏—Å–∫–∞–º
        cursor = db.connection.cursor()
        
        # –ü–æ–¥—Å—á–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞
        cursor.execute('''
        SELECT 
            COUNT(CASE WHEN final_risk_score > 7 OR is_suspicious = 1 THEN 1 END) as high_risk,
            COUNT(CASE WHEN final_risk_score > 4 AND final_risk_score <= 7 AND is_suspicious = 0 THEN 1 END) as medium_risk,
            COUNT(CASE WHEN final_risk_score <= 4 AND is_suspicious = 0 THEN 1 END) as low_risk,
            COUNT(*) as total
        FROM transactions
        ''')
        
        risk_stats = dict(cursor.fetchone())
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        cursor.execute('''
        SELECT 
            transaction_id,
            sender_name,
            beneficiary_name,
            amount_kzt,
            transaction_date,
            final_risk_score,
            risk_indicators,
            rule_triggers
        FROM transactions
        WHERE is_suspicious = 1 OR final_risk_score > 7
        ORDER BY final_risk_score DESC
        LIMIT 100
        ''')
        
        suspicious_transactions = []
        for row in cursor.fetchall():
            tx = dict(row)
            # –ü–∞—Ä—Å–∏–º JSON –ø–æ–ª—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if tx.get('risk_indicators') and isinstance(tx['risk_indicators'], str):
                try:
                    tx['risk_indicators'] = json.loads(tx['risk_indicators'])
                except:
                    pass
            if tx.get('rule_triggers') and isinstance(tx['rule_triggers'], str):
                try:
                    tx['rule_triggers'] = json.loads(tx['rule_triggers'])
                except:
                    pass
            suspicious_transactions.append(tx)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞
        risk_indicators_count = {}
        cursor.execute('SELECT risk_indicators FROM transactions WHERE risk_indicators IS NOT NULL')
        for row in cursor.fetchall():
            indicators = row['risk_indicators']
            if isinstance(indicators, str):
                try:
                    indicators = json.loads(indicators)
                    if isinstance(indicators, dict):
                        for key, value in indicators.items():
                            if value:
                                risk_indicators_count[key] = risk_indicators_count.get(key, 0) + 1
                except:
                    pass
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ —á–∞—Å—Ç–æ—Ç–µ
        top_indicators = sorted(risk_indicators_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        db.close()
        
        return jsonify({
            'risk_summary': {
                'high': risk_stats['high_risk'] or 0,
                'medium': risk_stats['medium_risk'] or 0,
                'low': risk_stats['low_risk'] or 0,
                'total': risk_stats['total'] or 0
            },
            'suspicious_transactions': suspicious_transactions,
            'top_risk_indicators': [{'name': name, 'count': count} for name, count in top_indicators],
            'last_updated': datetime.now().isoformat()
        })
    
    # –ï—Å–ª–∏ –ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
    return jsonify({
        'risk_summary': {
            'high': 0,
            'medium': 0,
            'low': 0,
            'total': 0
        },
        'suspicious_transactions': [],
        'top_risk_indicators': [],
        'last_updated': datetime.now().isoformat()
    })

# –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (–±–µ–∑ API –ø—Ä–µ—Ñ–∏–∫—Å–∞)
@app.route('/')
def index():
    return jsonify({
        'service': '–ê–§–ú –†–ö - –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π',
        'api_docs': '/api/',
        'health_check': '/api/health'
    })

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º Blueprint
app.register_blueprint(api_bp)

# –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ë–î
def find_latest_db():
    """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–æ–∑–¥–∞–Ω–Ω—É—é –ë–î –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global latest_db_path
    db_pattern = os.path.join(os.path.dirname(__file__), "aml_system_*.db")
    db_files = glob.glob(db_pattern)
    if db_files:
        # –ë–µ—Ä–µ–º —Å–∞–º—É—é –Ω–æ–≤—É—é –ë–î –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
        latest_db_path = max(db_files, key=os.path.getmtime)
        print(f"üîÑ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ë–î: {os.path.basename(latest_db_path)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –Ω–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        try:
            from aml_database_setup import AMLDatabaseManager
            db = AMLDatabaseManager(db_path=latest_db_path)
            cursor = db.connection.cursor()
            cursor.execute("SELECT COUNT(*) FROM transactions")
            count = cursor.fetchone()[0]
            print(f"üìä –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö {count} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
            
            # –ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–π –ë–î –Ω–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –∏—â–µ–º –ë–î —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏
            if count == 0:
                for db_file in sorted(db_files, key=os.path.getmtime, reverse=True):
                    temp_db = AMLDatabaseManager(db_path=db_file)
                    cursor = temp_db.connection.cursor()
                    cursor.execute("SELECT COUNT(*) FROM transactions")
                    trans_count = cursor.fetchone()[0]
                    temp_db.close()
                    
                    if trans_count > 0:
                        latest_db_path = db_file
                        print(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –ë–î —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏: {os.path.basename(db_file)} ({trans_count} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)")
                        break
            
            db.close()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ë–î: {e}")

# –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ë–î –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
find_latest_db()

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ: —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏
if os.path.exists(os.path.join(os.path.dirname(__file__), "aml_system_e840b2937714940f.db")):
    latest_db_path = os.path.join(os.path.dirname(__file__), "aml_system_e840b2937714940f.db")
    print(f"üéØ –Ø–≤–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ë–î: {os.path.basename(latest_db_path)}")

if __name__ == '__main__':
    print("=" * 50)
    print("–ê–§–ú –†–ö - –ë—ç–∫–µ–Ω–¥ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    print("=" * 50)
    print("–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8000")
    print("API –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–∞ http://localhost:8000/api/")
    print("–§—Ä–æ–Ω—Ç–µ–Ω–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:3000")
    print("=" * 50)
    
    app.run(host='0.0.0.0', port=8000, debug=True)