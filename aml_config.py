#!/usr/bin/env python3
"""
üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AML —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
–í–µ—Ä—Å–∏—è: 3.0

–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è:
- –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –ù–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ—Ñ–∏–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞
- –ü–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø—Ä–∞–≤–∏–ª
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
"""

import os
import json
import psutil
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from pathlib import Path


@dataclass
class ProcessingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    max_workers: int = field(default_factory=lambda: min(20, max(1, psutil.cpu_count() - 2)))
    batch_size: int = 100
    chunk_size: int = 1000
    
    # –õ–∏–º–∏—Ç—ã —Ä–µ—Å—É—Ä—Å–æ–≤
    max_memory_gb: float = 4.0
    max_cpu_percent: float = 80.0
    timeout_seconds: int = 300
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    use_parallel_json_loading: bool = True
    use_parallel_analysis: bool = True
    auto_optimize_workers: bool = True
    
    # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
    enable_result_cache: bool = True
    cache_ttl_minutes: int = 60
    
    def optimize_for_system(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ —Å–∏—Å—Ç–µ–º—É"""
        # –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
        memory_gb = psutil.virtual_memory().total / (1024**3)
        cpu_count = psutil.cpu_count()
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
        if memory_gb < 4:
            self.batch_size = 50
            self.max_workers = min(4, cpu_count)
            self.max_memory_gb = memory_gb * 0.7
        elif memory_gb < 8:
            self.batch_size = 100
            self.max_workers = min(8, cpu_count - 1)
            self.max_memory_gb = memory_gb * 0.8
        else:
            self.batch_size = 200
            self.max_workers = min(20, cpu_count - 2)
            self.max_memory_gb = memory_gb * 0.8
        
        print(f"üîß –ê–≤—Ç–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: {self.max_workers} –≤–æ—Ä–∫–µ—Ä–æ–≤, –±–∞—Ç—á {self.batch_size}")


@dataclass
class AnalysisConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤"""
    # –í–µ—Å–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π (–¥–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –¥–æ 1.0)
    profile_weights: Dict[str, float] = field(default_factory=lambda: {
        'transaction': 0.40,
        'network': 0.30,
        'customer': 0.15,
        'behavioral': 0.10,
        'geographic': 0.05
    })
    
    # –ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ê–§–ú –†–ö (–≤ —Ç–µ–Ω–≥–µ)
    thresholds: Dict[str, float] = field(default_factory=lambda: {
        'cash_operations': 2_000_000,      # 2 –º–ª–Ω —Ç–µ–Ω–≥–µ
        'international_transfers': 1_000_000,  # 1 –º–ª–Ω —Ç–µ–Ω–≥–µ
        'domestic_transfers': 7_000_000,   # 7 –º–ª–Ω —Ç–µ–Ω–≥–µ
        'suspicious_amount': 10_000_000,   # 10 –º–ª–Ω —Ç–µ–Ω–≥–µ
        'high_risk_amount': 50_000_000     # 50 –º–ª–Ω —Ç–µ–Ω–≥–µ
    })
    
    # –û—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞
    risk_scores: Dict[str, Dict[str, float]] = field(default_factory=lambda: {
        'transaction': {
            'threshold_exceeded': 3.0,
            'round_amount': 2.0,
            'unusual_time': 1.5,
            'suspicious_purpose': 3.0,
            'multiple_patterns': 2.0
        },
        'network': {
            'circular_scheme': 8.0,
            'star_pattern': 6.0,
            'smurfing': 7.0,
            'transit_chain': 5.0,
            'high_centrality': 4.0
        },
        'geographic': {
            'offshore_zone': 5.0,
            'sanctioned_country': 8.0,
            'fatf_blacklist': 10.0,
            'fatf_greylist': 5.0,
            'high_risk_corridor': 3.0
        },
        'behavioral': {
            'volume_spike': 4.0,
            'frequency_change': 3.0,
            'new_geography': 2.0,
            'dormant_activation': 5.0,
            'pattern_deviation': 3.0
        },
        'customer': {
            'pep_status': 6.0,
            'high_risk_business': 4.0,
            'sanctions_match': 10.0,
            'adverse_media': 3.0,
            'kyc_incomplete': 2.0
        }
    })
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∏—Å–∫–æ–≤
    risk_categories: Dict[str, Dict[str, float]] = field(default_factory=lambda: {
        'thresholds': {
            'low': 3.0,
            'medium': 5.0,
            'high': 7.0,
            'critical': 9.0
        },
        'actions': {
            'pass': 3.0,
            'monitor': 5.0,
            'edd': 7.0,    # Enhanced Due Diligence
            'str': 7.0     # Suspicious Transaction Report
        }
    })
    
    # –ë–æ–Ω—É—Å—ã –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    multi_indicator_bonus: float = 0.5
    max_bonus_points: float = 2.0
    
    def validate_weights(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤–µ—Å–æ–≤ –ø—Ä–æ—Ñ–∏–ª–µ–π"""
        total_weight = sum(self.profile_weights.values())
        if abs(total_weight - 1.0) > 0.001:
            print(f"‚ö†Ô∏è –°—É–º–º–∞ –≤–µ—Å–æ–≤ –ø—Ä–æ—Ñ–∏–ª–µ–π: {total_weight:.3f} (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 1.0)")
            return False
        return True


@dataclass
class CountryRiskConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–æ–≤—ã—Ö —Ä–∏—Å–∫–æ–≤"""
    # FATF —Å–ø–∏—Å–∫–∏ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ)
    fatf_blacklist: List[str] = field(default_factory=lambda: [
        'IR',  # –ò—Ä–∞–Ω
        'KP'   # –°–µ–≤–µ—Ä–Ω–∞—è –ö–æ—Ä–µ—è
    ])
    
    fatf_greylist: List[str] = field(default_factory=lambda: [
        'AF', 'AL', 'BB', 'BF', 'KH', 'CM', 'HR', 'GH', 'GI', 'JM', 
        'JO', 'ML', 'MZ', 'MM', 'NI', 'PK', 'PA', 'PH', 'SN', 'SO', 
        'SS', 'SY', 'TR', 'UG', 'AE', 'VU', 'YE'
    ])
    
    # –û—Ñ—à–æ—Ä–Ω—ã–µ –∑–æ–Ω—ã
    offshore_zones: List[str] = field(default_factory=lambda: [
        'AD', 'AG', 'BS', 'BH', 'BB', 'BZ', 'BM', 'VG', 'KY', 'CK',
        'CW', 'CY', 'DM', 'GI', 'GG', 'GD', 'HK', 'IM', 'JE', 'KN',
        'LB', 'LR', 'LI', 'LU', 'MO', 'MT', 'MH', 'MU', 'MC', 'NR',
        'AN', 'NU', 'PA', 'WS', 'SM', 'SC', 'SG', 'LC', 'VC', 'CH',
        'TO', 'TC', 'VU', 'VE'
    ])
    
    # –°–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã
    sanctioned_countries: List[str] = field(default_factory=lambda: [
        'RU', 'BY', 'IR', 'KP', 'AF', 'MM', 'SY'
    ])
    
    # –°—Ç—Ä–∞–Ω—ã –ï–ê–≠–° (–Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫)
    eaeu_countries: List[str] = field(default_factory=lambda: [
        'KZ', 'RU', 'BY', 'AM', 'KG'
    ])
    
    def get_country_risk(self, country_code: str) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∏—Å–∫–∞ —Å—Ç—Ä–∞–Ω—ã"""
        if not country_code:
            return 5.0
        
        country_code = country_code.upper()
        
        if country_code in self.fatf_blacklist:
            return 10.0
        elif country_code in self.sanctioned_countries:
            return 8.0
        elif country_code in self.fatf_greylist or country_code in self.offshore_zones:
            return 5.0
        elif country_code in self.eaeu_countries:
            return 1.0
        else:
            return 3.0  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫


@dataclass
class DatabaseConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    database_path: str = "aml_system.db"
    connection_pool_size: int = 10
    query_timeout: int = 30
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    enable_wal_mode: bool = True
    enable_foreign_keys: bool = True
    cache_size_mb: int = 64
    temp_store_memory: bool = True
    
    # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    indexes: Dict[str, List[str]] = field(default_factory=lambda: {
        'transactions': [
            'idx_tx_date', 'idx_tx_amount', 'idx_tx_sender', 'idx_tx_beneficiary',
            'idx_tx_risk_score', 'idx_tx_suspicious'
        ],
        'customer_profiles': [
            'idx_customer_id', 'idx_customer_risk', 'idx_customer_country'
        ],
        'network_connections': [
            'idx_network_source', 'idx_network_target', 'idx_network_amount'
        ],
        'behavioral_history': [
            'idx_behavior_customer', 'idx_behavior_date'
        ]
    })
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è
    archive_after_days: int = 365
    cleanup_temp_tables: bool = True


@dataclass
class MonitoringConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_level: str = "INFO"
    log_file_path: str = "logs/aml_system.log"
    max_log_size_mb: int = 100
    backup_count: int = 5
    
    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    enable_performance_monitoring: bool = True
    monitoring_interval_seconds: int = 5
    alert_cpu_threshold: float = 90.0
    alert_memory_threshold: float = 85.0
    alert_disk_threshold: float = 90.0
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    collect_processing_metrics: bool = True
    metrics_retention_days: int = 30
    
    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
    enable_alerts: bool = True
    alert_email: Optional[str] = None
    webhook_url: Optional[str] = None


class AMLConfigManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ AML —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, config_file: str = "aml_config.json"):
        self.config_file = config_file
        self.processing = ProcessingConfig()
        self.analysis = AnalysisConfig()
        self.country_risk = CountryRiskConfig()
        self.database = DatabaseConfig()
        self.monitoring = MonitoringConfig()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞
        self.load_from_file()
        
        # –ê–≤—Ç–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        if self.processing.auto_optimize_workers:
            self.processing.optimize_for_system()
    
    def load_from_file(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        if not os.path.exists(self.config_file):
            print(f"üìÑ –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—é {self.config_file}")
            self.save_to_file()
            return
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            if 'processing' in config_data:
                self._update_dataclass(self.processing, config_data['processing'])
            
            if 'analysis' in config_data:
                self._update_dataclass(self.analysis, config_data['analysis'])
            
            if 'country_risk' in config_data:
                self._update_dataclass(self.country_risk, config_data['country_risk'])
            
            if 'database' in config_data:
                self._update_dataclass(self.database, config_data['database'])
            
            if 'monitoring' in config_data:
                self._update_dataclass(self.monitoring, config_data['monitoring'])
            
            print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.config_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    
    def save_to_file(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
        try:
            config_data = {
                'processing': self._dataclass_to_dict(self.processing),
                'analysis': self._dataclass_to_dict(self.analysis),
                'country_risk': self._dataclass_to_dict(self.country_risk),
                'database': self._dataclass_to_dict(self.database),
                'monitoring': self._dataclass_to_dict(self.monitoring),
                'metadata': {
                    'version': '3.0',
                    'last_updated': str(pd.Timestamp.now()),
                    'description': 'AML —Å–∏—Å—Ç–µ–º–∞ - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏'
                }
            }
            
            os.makedirs(os.path.dirname(self.config_file) if os.path.dirname(self.config_file) else '.', exist_ok=True)
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {self.config_file}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    
    def _dataclass_to_dict(self, obj) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ dataclass –≤ —Å–ª–æ–≤–∞—Ä—å"""
        result = {}
        for field_name, field_value in obj.__dict__.items():
            if isinstance(field_value, (str, int, float, bool, list, dict)):
                result[field_name] = field_value
            else:
                result[field_name] = str(field_value)
        return result
    
    def _update_dataclass(self, obj, data: Dict[str, Any]):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ dataclass –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        for key, value in data.items():
            if hasattr(obj, key):
                setattr(obj, key, value)
    
    def validate_configuration(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ –ø—Ä–æ—Ñ–∏–ª–µ–π
        if not self.analysis.validate_weights():
            errors.append("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≤–µ—Å–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ —Ä–µ—Å—É—Ä—Å–æ–≤
        if self.processing.max_workers <= 0:
            errors.append("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
        
        if self.processing.batch_size <= 0:
            errors.append("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if self.analysis.thresholds['cash_operations'] <= 0:
            errors.append("–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –Ω–∞–ª–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞–Ω–æ–≤—ã—Ö —Å–ø–∏—Å–∫–æ–≤
        if not self.country_risk.fatf_blacklist:
            errors.append("FATF blacklist –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        if errors:
            print("‚ùå –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
            for error in errors:
                print(f"  ‚Ä¢ {error}")
            return False
        
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω–∞")
        return True
    
    def get_optimal_settings(self, data_size: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if data_size < 1000:
            return {
                'use_parallel': False,
                'workers': 1,
                'batch_size': data_size
            }
        elif data_size < 10000:
            return {
                'use_parallel': True,
                'workers': min(4, self.processing.max_workers),
                'batch_size': 100
            }
        else:
            return {
                'use_parallel': True,
                'workers': self.processing.max_workers,
                'batch_size': self.processing.batch_size
            }
    
    def print_summary(self):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        print(f"\nüìã –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø AML –°–ò–°–¢–ï–ú–´")
        print(f"{'='*60}")
        print(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞:")
        print(f"   –ú–∞–∫—Å. –≤–æ—Ä–∫–µ—Ä–æ–≤: {self.processing.max_workers}")
        print(f"   –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.processing.batch_size}")
        print(f"   –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏: {self.processing.max_memory_gb:.1f} GB")
        print(f"   –¢–∞–π–º–∞—É—Ç: {self.processing.timeout_seconds} —Å–µ–∫")
        
        print(f"\n‚öñÔ∏è –ê–Ω–∞–ª–∏–∑:")
        print(f"   –í–µ—Å–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π: {self.analysis.profile_weights}")
        print(f"   –ü–æ—Ä–æ–≥–∏ (–º–ª–Ω —Ç–µ–Ω–≥–µ): {{{k}: {v/1_000_000:.1f} for k, v in self.analysis.thresholds.items()}}")
        
        print(f"\nüåç –°—Ç—Ä–∞–Ω–æ–≤—ã–µ —Ä–∏—Å–∫–∏:")
        print(f"   FATF blacklist: {len(self.country_risk.fatf_blacklist)} —Å—Ç—Ä–∞–Ω")
        print(f"   FATF greylist: {len(self.country_risk.fatf_greylist)} —Å—Ç—Ä–∞–Ω")
        print(f"   –û—Ñ—à–æ—Ä–Ω—ã–µ –∑–æ–Ω—ã: {len(self.country_risk.offshore_zones)} –∑–æ–Ω")
        
        print(f"\nüíæ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:")
        print(f"   –ü—É—Ç—å: {self.database.database_path}")
        print(f"   –ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {self.database.connection_pool_size}")
        print(f"   WAL —Ä–µ–∂–∏–º: {self.database.enable_wal_mode}")
        
        print(f"\nüìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:")
        print(f"   –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–æ–≤: {self.monitoring.log_level}")
        print(f"   –ò–Ω—Ç–µ—Ä–≤–∞–ª: {self.monitoring.monitoring_interval_seconds} —Å–µ–∫")
        print(f"   –ê–ª–µ—Ä—Ç—ã –≤–∫–ª—é—á–µ–Ω—ã: {self.monitoring.enable_alerts}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config_manager = AMLConfigManager()


def get_config() -> AMLConfigManager:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    return config_manager


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    import pandas as pd
    
    config = get_config()
    config.validate_configuration()
    config.print_summary()
    
    # –ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö:")
    for size in [500, 5000, 50000]:
        settings = config.get_optimal_settings(size)
        print(f"   {size:,} –∑–∞–ø–∏—Å–µ–π: {settings}")